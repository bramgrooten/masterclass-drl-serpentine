gamma: 0.99
training_start: 1000
training_interval: 4
batch_size: 32
priority_replay: False

exploration_config:
    epsilon_init: 1.0
    epsilon_min: 0.02
    epsilon_decay: 0.997

replay_buffer_config:
    replay_capacity: 10000
    add_last_samples: 3

network_config:
    double_q: True
    copy_steps: 500
    dueling_architecture: False
    noisy: False
    gradient_clipping: True
    gradient_clipping_norm: 40.0
    learning_rate: 0.0001
    loss: 'mse'
    optimizer: 'adam'

    use_cnn :  False

    mlp_n_hidden: [256, 256]
    mlp_act_f: 'relu'

    mlp_value_act_f: 'tanh'
    mlp_value_n_hidden: 512
